Homework 2
================
Jingyi Zhang

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ─────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read participation data. For 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8.
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

Read and clean the NYC Transit Subway Entrance and Exit dataset.

``` r
transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE", .default = NULL))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains information on NYC transit. Variables included in
this dataset are line, station name, station latitude/longitude, routes
served, entry, entrance type, vending, and ADA compliance. This dataset
has 1868 rows and 19 columns. So far, all column names are converted to
lowercase and snakecase form. Then, the uninterested columns are removed
from the dataset. The entry variable is converted from character to a
logical variable with values of “TRUE” or “FALSE”. This dataset at this
stage is not tidy yet. The routes served columns (route1-route11) should
be combined into one single column.

How many distinct stations are there?

``` r
select(transit_df, line, station_name) %>%
  distinct(line, station_name) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   465

How many stations are ADA compliant?

``` r
filter(transit_df, ada == "TRUE") %>%
  select(ada, line, station_name) %>% 
  distinct(ada, line, station_name) %>% 
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

What proportion of station entrances/exits without vending allow
entrance?

``` r
filter(transit_df, entry == "TRUE", vending == "NO") %>%
  select(line, station_name, entry, vending) %>%
  distinct(line, station_name, entry, vending) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    43

``` r
43/465
```

    ## [1] 0.09247312

Reformat data that makes route number and route name distinct variables.

``` r
transit_tidy_df = 
  mutate_at(transit_df, vars(route8:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
  ) %>%
  drop_na(route_number)
```

How many distinct stations serve the A train?

``` r
filter(transit_tidy_df, route_number == "A") %>%
  select(route_number, line, station_name) %>%
  distinct(route_number, line, station_name) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    60

Of the stations that serve the A train, how many are ADA compliant?

``` r
filter(transit_tidy_df, route_number == "A", ada == "TRUE") %>%
  select(route_number, ada, line, station_name) %>%
  distinct(route_number, ada, line, station_name) %>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

## Problem 3

First step: Clean the data in pols-month.

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = TRUE)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )
  
pols_month = 
  left_join(pols_month, month_df, by = "month")

pols_month_tide_df =
  mutate(pols_month, president = case_when(
    prez_gop == "1" ~ "gop",
    prez_dem == "1" ~ "dem"
  ))

pols_month_tide_df = 
  select(pols_month_tide_df, -month, -day, -prez_gop, -prez_dem) %>%
    relocate(month_name, .after = year)
```

Second step: clean snp dataset.

``` r
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), convert = TRUE)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp_df = 
  left_join(snp_df, month_df, by = "month")

snp_tidy_df =
  select(snp_df, -month, -day) %>%
    relocate(month_name, .after = year)
```

Third step: clean the unemployment data.

``` r
unemployment_df = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  mutate_at(vars(jan:dec), as.character)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemployment_tidy_df =
  pivot_longer(
    unemployment_df,
    jan:dec,
    names_to = "month_name",
    names_prefix = NULL,
    values_to = "percentage_of_unemployment"
  )
    
unemployment_tidy_df =
  mutate(unemployment_tidy_df, month_name = month.name[as.factor(month_name)])
```

Join the pols\_month, snp, and unemployment datasets.

``` r
pols_snp_df =
  left_join(pols_month_tide_df, snp_tidy_df, by = c("month_name", "year"))

pols_snp_unemployment_df =
  left_join(pols_snp_df, unemployment_tidy_df, by = c("month_name", "year")) %>% view
```
