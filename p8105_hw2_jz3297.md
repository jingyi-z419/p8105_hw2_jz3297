Homework 2
================
Jingyi Zhang

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read participation data. For 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8.
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

Read and clean the NYC Transit dataset.

``` r
transit_df =
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE", .default = NULL))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains information on NYC transit. Variables included in
this dataset are line, station name, station latitude/longitude, routes
served, entry, entrance type, vending, and ADA compliance. This dataset
has 1868 rows and 19 columns. So far, all column names are converted to
lowercase and snakecase form. Then, the uninterested columns are removed
from the dataset. The entry variable is converted from character to a
logical variable with values of “TRUE” or “FALSE”. This dataset at this
stage is not tidy yet. The routes served columns (route1-route11) should
be combined into one single column.

  - The number of distinct stations is 465.

  - The number of stations that are ADA compliant is 84.

  - Proportion of station entrances/exits without vending allow entrance
    is 0.4343434.

Reformat the transit dataset that makes route number and route name
distinct variables.

``` r
transit_tidy_df = 
  mutate_at(transit_df, vars(route8:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
  ) %>%
  drop_na(route_number)
```

  - The number of distinct stations that serve the A train is 60.

  - The number of stations that serve the A train and are ADA compliant
    is 17.

## Problem 3

First, clean the pols-month dataset.

``` r
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = TRUE)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )
  
pols_month = 
  left_join(pols_month, month_df, by = "month")

pols_month_tidy_df =
  mutate(pols_month, president = case_when(
    prez_gop == "1" ~ "gop",
    prez_dem == "1" ~ "dem"
  ))

pols_month_tidy_df = 
  select(pols_month_tidy_df, -month, -day, -prez_gop, -prez_dem) %>%
    relocate(month_name, .after = year)
```

Second, clean the snp dataset.

``` r
snp_df = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), convert = TRUE)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp_df = 
  left_join(snp_df, month_df, by = "month")

snp_tidy_df =
  select(snp_df, -month, -day) %>%
    relocate(month_name, .after = year)
```

Third, clean the unemployment dataset.

``` r
unemployment_df = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  mutate_at(vars(jan:dec), as.character)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemployment_tidy_df =
  pivot_longer(
    unemployment_df,
    jan:dec,
    names_to = "month_name",
    names_prefix = NULL,
    values_to = "percentage_of_unemployment"
  )
    
unemployment_tidy_df =
  mutate(unemployment_tidy_df, month_name = month.name[as.factor(month_name)])
```

Join the pols-month, snp, and unemployment datasets.

``` r
pols_snp_df =
  left_join(pols_month_tidy_df, snp_tidy_df, by = c("month_name", "year"))

pols_snp_unemployment_df =
  left_join(pols_snp_df, unemployment_tidy_df, by = c("month_name", "year"))
```

The pols-month dataset contains information related to the number of
national politicians who are either democratic or republican from 1947
to 2015. After cleaning and tidying, this dataset contains information
on year, month, the number of governors, senators, and representatives
for each party, and the indicator of whether the president was
republican or democratic is displayed in a single column named
“president”. The final dataset contains 822 rows and 9 variables.

The snp dataset contains information on date and Standard & Poor’s stock
market index. The final dataset after cleaning and tidying contains
information on year, month, and the stock market index with 787 rows and
3 columns.

The unemployment dataset contains information on year and percentage of
unemployment in each month of the associated year. After cleaning and
tidying, this dataset now contains information on year, month , and
percentage of unemployment. The orginal dataset lists months as separate
columns are combined into a single column. The final dataset contains
816 rows and 3 columns.

At the end, pols-month, snp, and unemployment datasets are merged to one
dataset. This dataset contains year, month, number of governors,
senators, and representatives for each party, president’s political
party, stock market index, and percentage of unemployment. This dataset
has a total of 822 rows and 11 columns.
